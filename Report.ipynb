{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Deep Reinforcement Learning Nanodegree Navigation Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "\n",
    "The agent uses the following tools, notions and techniques to solve the environment:\n",
    "- **Deep Q Learning**: the Q-value function, which maps state values to action values and lets the agent pick the *best* action (the one most likely to optimize the total reward), is approximated by a neural network\n",
    "- **Fixed Q-Targets with soft updates**: the algorithm uses two separate *local* and *target* networks with identical architectures, the local network is used as policy and the target network is updated with soft updates to smooth learning\n",
    "- **Epsilon-greedy action selection with epsilon decay**: the agent picks a random action with a probability of $\\epsilon$ which decays over time, to prevent the agent's actions from locking it into too specific situations\n",
    "- **Experience Replay**: instead of learning at every step from the experience it just got, the agent stores every experience (state, action, next state, reward and done flag) in a fixed-size memory and, every few steps, samples a batch of experiences to learn from\n",
    "- **Prioritized Experience Replay**: uniform sampling of experiences draws more on frequent experiences than infrequent ones... it is especially harmful in our current context, since the experience of collecting a banana (good or bad) is much less frequent than the less meaningful experience of moving and nothing happening (i.e. `reward == 0`). Experiences are thus stored with a priority value (the TD error seems to be most frequently used for that purpose) and sampling is done in a prioritized way, to ensure that meaningful experiences are more likely to surface during learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network architecture\n",
    "\n",
    "The neural networks share the following architecture:\n",
    "- An input layer of `37` nodes corresponding to the 37 values defining a state of the environment\n",
    "- A first fully connected hidden layer with `64` nodes and a ReLU activation\n",
    "- A second fully connected hidden layer with `64` nodes and a ReLU activation\n",
    "- An output layer of `4` nodes corresponding to the 4 possible actions\n",
    "\n",
    "<img src=\"nn-architecture.png\">\n",
    "\n",
    "Note: apart from the input and output layers that are obviously tied to the environment, the architecture is the same as the one used in Udacity's DQN algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters\n",
    "\n",
    "- Memory\n",
    "  - Buffer size: $1e^5$ as in Udacity's DQN algorithm\n",
    "  - Minimum priority: $1e^{-5}$ (inverse of the buffer size) to ensure all experiences have at least a tiny chance to be sampled\n",
    "  - Priority factor: $90\\%$ as a first try value which seemed to work fine\n",
    "- Soft updates\n",
    "  - Tau $\\tau$: $1e^{-3}$ as in Udacity's DQN algorithm\n",
    "- Training\n",
    "  - Batch size: $64$ as in Udacity's DQN algorithm\n",
    "  - Gamma $\\gamma$ discount factor: $0.99$ as in Udacity's DQN algorithm\n",
    "  - Learning rate: $1e^{-4}$ which is 5 times smaller than the value used in Udacity's DQN algorithm, because smaller values seemed to help the algorithm learn faster\n",
    "  - Update interval: $4$ as in Udacity's DQN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "## Initial setup\n",
    "\n",
    "Please follow the instructions of `README.md` (found in the same root folder as the present notebook) to install the required packages and download the game environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "The following packages are required for the notebook to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from collections import deque, namedtuple, OrderedDict\n",
    "from IPython.display import Audio\n",
    "from torch.nn.functional import mse_loss\n",
    "from tqdm.notebook import trange\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        \"\"\"Build a neural network with a series of linear hidden layers and ReLU activation\n",
    "        :param list layer_sizes: sizes of all layers, from input to output,\n",
    "                                 e.g. [37, 64, 64, 4] for two hidden layers\n",
    "        \"\"\"\n",
    "        \n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        # Define the layers\n",
    "        layers = OrderedDict()\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            layers['fc{}'.format(i)] = nn.Linear(layer_sizes[i], layer_sizes[i+1])\n",
    "            if i + 2 < len(layer_sizes): # Last layer does not have a ReLU\n",
    "                layers['relu{}'.format(i)] = nn.ReLU()\n",
    "\n",
    "        # Define the model\n",
    "        self.model = nn.Sequential(layers)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Forward pass through the DQN to compute action values based on provided state\n",
    "        :param state: current state of the environment\n",
    "        :return: action values as per current policy\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.model(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 100000   # maximum number of prior experiences kept in memory\n",
    "MIN_PRIORITY = 1e-5    # minimum priority to ensure no experience is entirely unusable for learning\n",
    "PRIORITY_FACTOR = 0.9  # 0 = uniform sampling, 1 = fully prioritized sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples and retrieve them based on priorities\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, device):\n",
    "        \"\"\"\n",
    "        :param int batch_size: size of each training batch\n",
    "        :param str device: device to use for training\n",
    "        \"\"\"\n",
    "        \n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Prepare storage of experiences\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "\n",
    "        # Initialize memory to store the experiences\n",
    "        self.memory = deque(maxlen=BUFFER_SIZE)\n",
    "        \n",
    "        # Initialize buffer to store the priority values associated with the experiences\n",
    "        self.priorities = deque(maxlen=BUFFER_SIZE)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done, priority):\n",
    "        \"\"\"Commit an experience to memory (and possibly eject the oldest experience, if buffer size is reached)\n",
    "        :param state: state of the environment before the agent acted\n",
    "        :param action: action the agent chose\n",
    "        :param reward: reward the environment bestowed on the agent\n",
    "        :param next_state: state of the environment after the agent acted\n",
    "        :param done: False if the episode is still ongoing\n",
    "        :param priority: importance of the experience (generally TD error)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare named tuple\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "\n",
    "        # Commit experience to memory\n",
    "        self.memory.append(e)\n",
    "        \n",
    "        # Save priority of experience (or minimum if the priority given is too low)\n",
    "        self.priorities.append(max(priority, MIN_PRIORITY))\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Randomly samples a batch of experiences based on their priorities\"\"\"\n",
    "        \n",
    "        # Prepare sampling probabilities\n",
    "        adjusted_priorities = np.array(self.priorities) ** PRIORITY_FACTOR\n",
    "        sampling_probabilities = list(adjusted_priorities / np.sum(adjusted_priorities))\n",
    "\n",
    "        # Sample experiences\n",
    "        indices = np.random.choice(len(self.memory), size=self.batch_size, p=sampling_probabilities)\n",
    "        experiences = [self.memory[idx] for idx in indices]\n",
    "\n",
    "        # Prepare data\n",
    "        states = torch.from_numpy(np.vstack([e.state\n",
    "                                             for e in experiences if e is not None])).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action\n",
    "                                              for e in experiences if e is not None])).long().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward\n",
    "                                             for e in experiences if e is not None])).float().to(self.device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state\n",
    "                                                  for e in experiences if e is not None])).float().to(self.device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None])\n",
    "                                 .astype(np.uint8)).float().to(self.device)\n",
    "\n",
    "        return states, actions, rewards, next_states, dones\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory\"\"\"\n",
    "        \n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAU = 1e-3  # Parameter of the soft update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_update(local_model, target_model):\n",
    "    \"\"\"Soft update model parameters: θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "    :param local_model: PyTorch model the weights are copied from\n",
    "    :param target_model: PyTorch model the weights are copied to\n",
    "    \"\"\"\n",
    "    \n",
    "    for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "        target_param.data.copy_(TAU * local_param.data + (1.0 - TAU) * target_param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64           # Size of the training batches\n",
    "GAMMA = 0.99              # Reward discount factor\n",
    "LAYERS = [37, 64, 64, 4]  # Dimensions of the DQN layers including input/state and output/action\n",
    "LR = 1e-4                 # Learning rate\n",
    "UPDATE_EVERY = 4          # Interval between updates of the target Q network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"Interacts with and learns from the environment\"\"\"\n",
    "\n",
    "    def __init__(self, device):\n",
    "        \"\"\"Initialize everything the agent needs to learn\n",
    "        :param str device: device to use for training\n",
    "        \"\"\"\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        # Save size of output layer\n",
    "        self.action_size = LAYERS[-1]\n",
    "\n",
    "        # Define the double Q networks\n",
    "        self.local_dqn = DQN(LAYERS).to(device)\n",
    "        self.target_dqn = DQN(LAYERS).to(device)\n",
    "        self.optimizer = optim.Adam(self.local_dqn.parameters(), lr=LR)\n",
    "\n",
    "        # Setup a prioritized replay buffer\n",
    "        self.memory = PrioritizedReplayBuffer(BATCH_SIZE, device)\n",
    "\n",
    "        # Initialize time step to update the target network only every UPDATE_EVERY steps\n",
    "        self.t_step = 0\n",
    "\n",
    "    def eval(self, state):\n",
    "        \"\"\"Returns complete output of local network for a given state (i.e. all action values)\n",
    "        :param state: state that will be fed to the local network\n",
    "        :return: complete output of the network\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare input\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
    "\n",
    "        # Get action values (with training mode OFF)\n",
    "        self.local_dqn.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.local_dqn(state)\n",
    "        self.local_dqn.train()\n",
    "\n",
    "        return action_values.cpu().data.numpy()[0]\n",
    "\n",
    "    def learn(self, experiences):\n",
    "        \"\"\"Learn from a batch of experience tuples\n",
    "        :param Tuple[torch.Tensor] experiences: batch of (s, a, r, s', done) tuples\n",
    "        \"\"\"\n",
    "        \n",
    "        # Unpack batch\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values from target network\n",
    "        q_targets_next = self.target_dqn(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        \n",
    "        # Compute Q targets\n",
    "        q_targets = rewards + (GAMMA * q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local network\n",
    "        q_expected = self.local_dqn(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = mse_loss(q_expected, q_targets)\n",
    "\n",
    "        # Back-prop\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Soft update of the target network\n",
    "        soft_update(self.local_dqn, self.target_dqn)\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Save experience in memory and learn every UPDATE_EVERY time steps\n",
    "        :param state: state of the environment before the agent acted\n",
    "        :param action: action the agent chose\n",
    "        :param reward: reward the environment bestowed on the agent\n",
    "        :param next_state: state of the environment after the agent acted\n",
    "        :param done: False if the episode is still ongoing\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute TD error to use as priority\n",
    "        td_error = abs(reward + GAMMA * max(self.eval(next_state)) - self.eval(state)[action])\n",
    "\n",
    "        # Commit experience to memory\n",
    "        self.memory.add(state, action, reward, next_state, done, td_error)\n",
    "\n",
    "        # Update time step\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "\n",
    "        # Learn every UPDATE_EVERY time steps if enough samples are available\n",
    "        if self.t_step == 0 and len(self.memory) > BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences)\n",
    "\n",
    "    def act(self, state, eps=0.0):\n",
    "        \"\"\"Returns an action for a given state as per current policy\n",
    "        :param state: state of the environment\n",
    "        :param eps: epsilon for epsilon-greedy action selection\n",
    "        :return: action chosen by the agent\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare input\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
    "\n",
    "        # Get action values from local network with training mode OFF\n",
    "        self.local_dqn.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.local_dqn(state)\n",
    "        self.local_dqn.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if np.random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy()).astype(np.int32)\n",
    "            # Note: without type conversion, argmax sometimes outputs a 64-bit integer that wrecks the UnityEnvironment\n",
    "        else:\n",
    "            return np.random.choice(np.arange(self.action_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unity Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the next line so that the `file_name` parameter matches the location of the Unity environment you downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Banana_Windows_x86_64/Banana.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An empty Unity window should have opened. If you switch to it during training or testing, you will be able to watch the agent in action.\n",
    "\n",
    "**Note**: if the environment is set to training mode, the action will be so fast, it might be uncomfortable to watch.\n",
    "\n",
    "Once the environment is launched, we need to connect to it via a *brain name*. In some Unity environments, there are more than one brain/agent to control, but in the present case, there is only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the default (and only) brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_WINDOW_SIZE = 100\n",
    "TARGET_AVG_SCORE = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(max_episodes=2000, max_t=300, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Trains the agent until it reaches the defined goal or the maximum number of episodes\n",
    "    :param int max_episodes: limit number of episodes to try to reach the goal\n",
    "    :param int max_t: upper limit of time steps (in case the environment itself never stops the episode)\n",
    "    :param float eps_start: initial value of epsilon for epsilon-greedy action selection\n",
    "    :param float eps_end: final value of epsilon for epsilon-greedy action selection\n",
    "    :param float eps_decay: decay value to decrease epsilon over time\n",
    "    :return: scores of all episodes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use CUDA if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initializations\n",
    "    agent = Agent(device)\n",
    "    eps = eps_start\n",
    "    _scores = []\n",
    "    score_window = deque(maxlen=SCORE_WINDOW_SIZE)\n",
    "    \n",
    "    # Episode loop\n",
    "    episode_iterator = trange(1, max_episodes + 1, desc=\"Training\")\n",
    "    for episode in episode_iterator:\n",
    "        # Reset score\n",
    "        score = 0\n",
    "\n",
    "        # Reset the environment in training mode\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "        # Fetch first state of the environment\n",
    "        state = env_info.vector_observations[0]\n",
    "\n",
    "        # Time steps loop\n",
    "        for t in range(max_t):\n",
    "            # Let the agent pick an action\n",
    "            action = agent.act(state, eps)\n",
    "\n",
    "            # Apply the chosen action on the environment\n",
    "            env_info = env.step(action)[brain_name]\n",
    "\n",
    "            # Extract the results of the action\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            reward = env_info.rewards[0]\n",
    "            done = env_info.local_done[0]\n",
    "\n",
    "            # Let the agent memorize and learn from the experience \n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "\n",
    "            # Update the score and state\n",
    "            score += reward\n",
    "            state = next_state\n",
    "\n",
    "            # Stop if the episode is finished\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Save the score\n",
    "        _scores.append(score)\n",
    "        score_window.append(score)\n",
    "\n",
    "        # Decrease epsilon\n",
    "        eps = max(eps_end, eps_decay * eps)\n",
    "\n",
    "        # Compute average score\n",
    "        avg_score = np.mean(score_window)\n",
    "\n",
    "        # Log\n",
    "        episode_iterator.set_postfix(score=score, average_score=avg_score, epsilon=eps)\n",
    "\n",
    "        # Save the model weights for comparison of behavior\n",
    "        if episode % SCORE_WINDOW_SIZE == 0:\n",
    "            torch.save(agent.local_dqn.state_dict(), 'checkpoint-{}.pth'.format(episode))\n",
    "        \n",
    "        # Stop if the goal is reached\n",
    "        if avg_score >= TARGET_AVG_SCORE:\n",
    "            torch.save(agent.local_dqn.state_dict(), 'checkpoint-solved-{}.pth'.format(episode))\n",
    "            episode_iterator.close()\n",
    "            break\n",
    "\n",
    "    return _scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b3e10a138945969152654f6f2eb514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=2000, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = train()\n",
    "Audio('notification.wav', autoplay=True) # This line will play a sound when training stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average score of episodes `1027` to `1127` is above `13`. Our agent has managed to reach the goal in fewer than 1800 episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot score evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2deZwcVdX3f2f2mWSy7xsTQlZIQhbCkrCEHYKAoCAICoo8LKKoz6NBZfEFAVkVQQUFAQVEFgUJCGQHEgKTQALZ94WEZLJPMpm17/tHd3VXV91bW1d1VXef7+eTTPetW3eprjr31LnnnktCCDAMwzCFQ1HYDWAYhmGyCwt+hmGYAoMFP8MwTIHBgp9hGKbAYMHPMAxTYJSE3QAndOvWTdTU1ITdDIZhmJxi4cKFO4UQ3Y3pOSH4a2pqUFtbG3YzGIZhcgoi2ihLZ1MPwzBMgcGCn2EYpsBgwc8wDFNgsOBnGIYpMFjwMwzDFBgs+BmGYQoMFvwMwzAFBgt+hmEiixAC/6zdjObWWNhNyStY8DMME1mmfbYNP315CX4/c3XYTckrWPAzDBNZ9h1qAQDsPNAcckvyCxb8DMNEFt4gMBhY8DMME3mIwm5BfsGCn2EYpsBgwc8wDFNgsOBnGIYpMFjwM0xI1NU3Ycz/ewdLt+4LuylMxHj6g/W4+I/zAiufBT/DhMScVXXY09CCJ99bH3ZTmIhxx3+WYeHGPYGVz4KfYZjIwt6cwcCCn2HChl0VbeFL5C8s+BmGYQoMFvwMwzAFBgt+hmGYAoMFP8NkgW37DmFfQ4v8IM9gRp7NuxtwsKlVeXzNjnq0tuVO6GgW/AyTBY6/ZyZOvG9mWhpPWOYOJ943C5f/+UPpsQ07D+L0h+bi/rdXZrlV3mHBzzBZYn+jWmNkFEQoPOfiLfKFdjsPNAEAagP0u/cbFvwMw0Qejs7pLyz4GYZhfEBE6O3EDhb8DMMwGZCLbyOBCX4i6k9Es4hoOREtJaIfJtK7ENG7RLQ68bdzUG1gmFwgd/REJl8IUuNvBfATIcRwAMcBuJGIRgCYCmCGEGIwgBmJ7wxTcOSipsjkB4EJfiHENiHEosTnegDLAfQFcAGAZxLZngFwYVBtYJgoEwWT8LQl2zBtybawm5EXLNq0F//93N9r+Z2nP8ZnCm+iTMiKjZ+IagCMAbAAQE8hxDYgPjgA6KE451oiqiWi2rq6umw0k2FCIUzF/8bnF+HG5xeF2IL84rq/+3stZ67Ygd0Nzb6WCWRB8BNRewCvALhZCLHf6XlCiCeEEOOFEOO7d+8eXAMZhoksEXgpCp0gFINABT8RlSIu9J8TQryaSN5ORL0Tx3sD2BFkGxgm6rBws4cKeJ1zEHNBQXr1EIAnASwXQjykO/Q6gG8nPn8bwGtBtYFhogxP7jJOKArgRinxvcQUEwFcCeAzIvo0kfZzAPcC+CcRfRfAJgBfD7ANDMMwARPsCB5E6YEJfiHE+1C3+bSg6mUYJv8QIRrEQl+Rm0umHoZhmHxAL/fDGASCmN9gwc/kFPPW7kTN1GlYvHlv2E2JNBPvnYnj7p5hmactJhdi1zzzMWqmTpMem75sO2qmTsOaHfXS4w+8vRI1U6fh+r8vVJZhZPxd7+Lk+2clvz82aw1qpk5DQ7O7aKbPL9iEmqnTUFff5Oo8PTVTp+F//lablqa/Sr/89+euy5y3Jn7PLtmSumcvePR9DP7Fm47OL2KNnyl0Zq+Mr+mYv25XyC3xjyC0yC/2HsKX+xst86gE//Tlake7NxMLlD7dLF9U9NQH6wEAb33+pZNmAgB2HmjGxl0Nye9//3AjAGCvauMaBf+s3QwA2LS7wSanNW8v3Z72Xf/7PLdgk+vyZq6IX88F63Yn0xZv2YeWNme/OwUwucuCn2FCImyvnkzs5qrBKubjIKYvyY25I+zraiTTK5JT7pwMw0QbLzLaTgD7IfcjJrd9m1b2KsDZ1MMUPFETCpkQtrNIJqia7keXvJYR1OW0+53sBHrmvzObehiG8YkgBp5QXR8TdfstJsN0JQXY1MMweUkQk3dO8NMenyrT9yJd4/f1zPQyZTpwBLFylwU/Ezrz1+7Cxl0HfS936dZ9gYS0teKtz7Zhn0tvlKC15B37GzFrhdlTR1arsS3r6g7go/UpbxRNBr26aAvmrdmJ9TtTv9vCjXuUnkJOaYsJbNtn9kbasqcBd7y+FLsPmiNVLty4B6u210cq5tF/P/8Sew1RNdftPIjaDbsVZ6jJuSBtDOOEy/78IU6+f7arc5zIyimPvI+vPPq+t0Z5YNu+Q7j+uUW44fmFjvJnS9H/2p/m4+qnPzalywYcvZAHgFMfnINLHp9vyvfhut24/C8LMPmB2cm0i/84L+O2Pjt/gzR91so6PD1vA67+60emYxf/cR7OfHhu8rvvph6XI8rOA0247u8Lce2z6ffB8ws24Wt/Ml9LO9jUwzARnt3VBMTaHf6/vWSC5tduFPQyeVbfaL1oKujLv/NAavGVEMIkdDdm6KNvRUzxtuLVVLOm7kD8/AxfRXjlLsNEmLKS+OPU2NoWckvkGAVQFL2KMmlTpv1pUxTgttzihIre1OLPfcAaP8PkAE0tsbCbIMUkvyIo+P2YHPYqKFXzE26bpE2aN7f5cx+w4GeYCKNphk2R1fiNpp7oSf5MJroz7Y/Ky8muTaY3qcRfpyEZ7GBTD8MkiKTQSrTJrdaarZ4Y22XXTpnAC3pCWl+jTN5aVa/l9yoovXskpZ/nt5tsUQBSmgU/w4REtrcTNA6WdppsGD75qglWN3gdnGIKy4xdi0yX0efrxho/Eypb9jRgwq+nY3OAnhVBMm/tTpx8/yw0SibdGppbcdJ9s/ChRdTP6cu2Y9JvZmLivTMxf60kXwiC8uI/zsPLC7cojz+3YGPys15AXfnkAjw9b0Py+w9e+MR0rkxzlQmh8x99H//+5Atp/UIIfP7FPtRMnZbm+qlCX+PaugO4/fWl0nybd5vvRa25Vz65AADw5PvrUTN1Gu55a3myLef87j28sWSrtEynk7uPzlyNr/7hA7QmbPjGs/Rj13F3z8DSrfZrSa555mP85b110mNs42dC5eWFW7CjvgkvWQiaoMlE+7nzjeXYuKsBa3YcMB1b+WU9Nu1uwD1vrVCeP/XVJdiy5xC+2HsoKUz0hGF8WrhxD/73pcXK47/4Vyp+vF6Avbd6J34/c03y++uLzcLQqeljyZZ9uPnFT6XHhAB+P3M1AKQt9lKhH2ye0Q1MGtqq3JcS9+Iri8z34p7EAro731gGAHh8TlygtrQJLN+2Hzf/Q95WZX8NyQ+8swqfbNqLg01xBcJs408lfLm/ER9v2CMvV8f05Ttw1zTzPQVwkDYmZJJCNwJ+gF6aoJk2LDUoi4L1h9w8iyqTSqbzFG4nQt3W58fPLODOZKSvU3ae1mfNZdKNXV7rv+r3V07uKq6blm78Hfw3kbGphwkR7YEJX+xnhuytQdMkrfrm2tZrk54pbicj3bbDj0nKmBCuBih9Xqv6ixOSS38NnP4+qrdGpTunze9qMvH7/IOzqYeJBBFQ+D2RfPAlD5KTZyvtgZYUotIMVQIs00m7VreC32UeqY3fZZOFcHe/6LPKBLE2QBcl7B8qu7wlij649ePX0oNeGMexephQiUK0hEy0H7tXfVftcFVvMLgV/G41eJWXi9s63dQbc6jxlyQEv94LyN5LKfH7O6hbj9JUl0g3e0tZNsM1HJ2TiQRR9KF3QqZ+3vpey57FrJt6XC4QctIOO8HrRQbpxyc3i6GsxrXihHO7m8FPy6rqg1eN35jBzUDnxCzEph4mVGQ34L5DLdhus6l32KzVgmXpvje3xrBB4mWiPYcHmlqxde8hZZmyZ1EtIFJHtLDC63ceREvCHfBgUxu+sKhLT2NLG9bVHcDaugNo0ankWnmWv4cTwR+zFvxuESK9HLsi9bLXGCkUSF334sSHVt3gZ7XJ+ta9h7D/UEuijPjJjS1tae6g+nau3l5v2+bPvtiHlraY2cavbEUc/W+971B6CO8WSZgH9uNnIoH+QZh070wce/cMX8pd8eV+X8oxctqDc7Cu7kBSu7rhuUU47/fv4ZQHZmNXIhqkcVA7/9H3ccK9M9PSvMpB/Xlj73wXuw40YfIDs5M+6tOXb8dEQ10qfvTipzj1wTk47cE5aXsYTH5gNm577XNMfmC28vdwIsj1NvNPNu111CYrjHXat8DZRS5OmHr+9mFqnUJDc2p9xrKt6ffSCffOxHm/Tw/R/f3nF+HE+2YlNX29zD3j4bmYvdK8h4Geq//6Me56Y5npvrC7zvrf+hTD2gbNBVUPa/xMqMh2Nqpvsg7j64YvJRtw+EVdfVOaSFm1Pf4WcEDR/nV1srcBOzOFM6F1KLGATC+onDJLJ4yMG5bMXbVTulFJsn0OytebO5y+hWh0riqV1pmu8dvY4R3OKxTZOLev22leq6FdG+02nrWyLl6n0AR/etu09R5Wps0P1+3OyMa/17Bpj2xhIAt+JhIEZeEvcRCUxOszUFRE0oYbX6Odzl/IBkH9Ay8szBta+OZMMUYBbbWRmk4GJr2QLi2WtVP9C5RI8gsh0oS5nUneTlvWjhfbSMNDFoOq8UytSmPd5NB/2ezV47c7J5t6mDwmiGBUybLlcj+JEztq2uSuTd5WC1u5XzZboz3Yzq9fO2wlmPRFlha7a6es3JhIH0ztBlY7kan1odhG45eF5dDQBKlWgkrjd9omtzZ+t7A7JxMJgvJScaLxe4WIfNXE7JQwq4VFypWgLttnjPduFwbYSfRQ/eSu7M3Eqt/S5gujV49lEx0cT2j8NoL/kJXg1/4mPiQFv8eNWMwrd/19QHLKnZOIniKiHUT0uS7tDiL6gog+Tfw7N6j6Gf9JvfkGI/ntHuZMKCKStlrrU7JvVl3THZNp7fpz9dq4SaAr6nC71L+51Z3Gr9VrlU8v/NwOxLJSM1m5a4Wt4G+2MHtpv3nig3Y5vG69aBrYfX48cs3G/zSAsyXpDwshjk78ezPA+hmfScXqCab8EheC3612XETOHkirPGmHZH78uhzWGr8cOxu9EbPGb2PjT/y10kjbFCaqZJwjq/Il5cYnd1PfndrwlXUk/vqh8RvrNA6IWj7b+8alV49bcsrUI4SYC8DsiMvkLJrm8dyCTfjGE/OxZY/z8MzPzt+ARZusoxS61fg/3bwXT3+wPi2ttS2Gu99cnnTT1CCQVHNbunWfMhwuAPxpztrkZ71ga2qN4c43lqG+sUV2Gp76YAMWbtyD1dvr8ZguCiYAPPTOKuk5Rrm/60AT7n5zOVrbYtixvxH3vrUiLY9R429qtRb8mkBSyaVn529IE1oPvZtq5xkPz8Xq7fV4bsEmZfl7GszXQhhW7t41bTnmrKrDk++vN+W9+83l+Pen8pDJGvWNrfj5vz6T+vjrsbLx729sjfvPa6aemMBD765SRg9dqfPpl2G8r+5/e6VlfiMzlm9P+270bgticrfE9xLt+T4RfQtALYCfCCGk0oCIrgVwLQAMGDAgi81j7DjQ1IoP1+3G9X9f5Pic216L+6xvuHeKMo9bwX/hYx8AAK6aODCZNmPFDjwxd51p8RUpNP7rEn1446ZJ0jrufWsFvnfi4aa2Ld68F4s3x/3cbz1vBID08h+ZsRqPzFiNDhUl2N+Y7jL6Yu1maV1xjb84+f3W1z7Hm599iQk1XfDshxsxd1VdWn47Dd+I1j6VLfu215bitkRfgPQwymt2HMDlf1ngqj4gru3rFennF2zC84nB47uTBqblfWKuegDW87zF4KPR0GztZnz/2yuSmvTGXQ14ZMZqUx5N3l79148tyzJeztkr6+QZFXz3mdrk57aYwE9eSg8bnWumHhl/BDAIwNEAtgF4UJVRCPGEEGK8EGJ89+7ds9U+xgLj/edW8PjSBpuHQLPTthomOouInJl6JGnaHrqyY3bRIa1MDlZlAUBzqzYZK9As2cfX2Ec73Jp6zPXZ/94dKtJ1SQF3Nn6/OGSz4b2+n25NbEb87F5rTJje5HLK1CNDCLFdCNEmhIgB+DOACdmsn/EXv59nV1EcXdZtN09pNaA0WggRN949drgNs+w6SFsiv7CQc8Z5Az3FTtZZGC6I2+icfmHlxx+Hkr+dagB1KnD97J5scM0prx4ZRNRb9/WrAD5X5WWiR/AbbWf+CKlKIHh359TsxbLT9Q+lyo/dKW79yL1uDm4VyvigxUpsJ5Y44z1ijNWTLaxs/EC8nZqzgvdN1uP4+UbTGhOm+yyI5y4wGz8RvQDgFADdiGgLgNsBnEJERyN+L28A8D9B1c/kHm6eH7uHwXjcbgFXqg3mXJaLgfTnOijfCqNAtuujlXYuQ7VCVY8qhAXgTUAKiFA2bbczsRFS17clU8Gf0dnpSPcgCMDYE5jgF0JcJkl+Mqj6mOAJ4gb0ituFQKrJ3eRxi75pph7ZG4k+Zkymip9bm73RFmxHagGXheBvVAt+J3M6ZldJ/0MYOMEuDpJ+UG2LkI2/pS1mHvDzYHKXYZQ4eYDsBh/VUSGsTUlWx/Y0NCuFl5/PZGtMOLBNp3Ar+FMhG9R5dlkEebNbGSxDCLPpIhvYmXr0cY6UNn7HNhZ/TT1GgljXGIY7J5OjuLU1fvfpjzFjxQ5LF049X3n0fbz+/YkY1a8TJt47E1/sPYTK0mIsv9O8DtDLo2b1Rm8lnL75lwX47qSB8jwE/HraMvz5vfWY/uOTPLQqxf+9tBi1G/dg6a/OQrvy1KOpmiB1K/gnG0IAy5izSu2K6MT7xejLf9qDczCgS5U0b83UabbleUXlk6/x0sItyc/X/m2hIs/mZOhsK65z4dZsR/vyEsnbao5P7jKFxYwV1vHMZXywJh6WVgsJ7MYdElAPCAI2q3JttOEXPtqknNz983vrLc91Su3G+JKWegtzi55M3RDd4kXjb2qNhTK56weff5Ee079Xh4rA6xzZt6MpLefdOZncxqh5BOFt4JeQkHmXWL0n2HkUqboaxGu4OTywPJ9bd04/aV/u3FiQm2LfzNBe1b6Wd3T/Tqa0NiEkjgms8TMhEoTmYbSd200EZrTZukXRdh4rRPKQD2nunJ5blo6xHFW7M3VDzBY5qvCb8Fv+ymJTtWXJnZMFPxMqxpvcr8XA5oCY1jp9cuJTkUv17OnT/Xpb0RZa2bmKhrFy2gu5auoJGtkuYtm6Viz4GccEvYALCO7GFzZuhU5cDmVZ9OavLJvcXbt/hgXLfTkyM2FbjE09TAFgNmsEZ+O3Ktmr2URfj1/7FJgHP3m5Ydr43fxOrPHLkQUljMXka1D8hsJYXOGW6oHVYtzt48JuRs6xp6EZ1RWlJltiU2sMTS1t6FBp3hzbii/3NWLDLrmb3HGHdzWlfbhuV/KY/rMeIYAF61MbTPftVIl+navS0o47vCtaYwL1jS040NSKL/YcQr/OVcmw0AO7tUNbTKBXxwrsbWjBqu31ph23BnVvj7V15g24Nfp3qcLm3Q2oLCvG6H6dku3VKC4i6WKk/p2rsDnRjt4dK7Ftn7sNymUc1rUd2peXYPWOejS3xtCvcxW27TtkGpzalZdYhlgIkuIicjxYlpcUJwPd5TKdqsqwtyF9nUNVWYltJFA35VVXlJpCfR87sKtn4T/n6jkLhRDjjensx5+ntLTFsPLLenSsLMXw3h3Sji3evBcxIaTCOgp8sdcsPFdvr8e+Qy3oUW12qdN8thtbY+iUGMyMAtpK6APA5t3Wews4ee78EPoAsNEwuKr2PQhLZ5PZpq2JvnIZFWT7O+RUrB4/Gdp1KGZfNTvsZuQUW/Y0YNJvZqFvVSVmX3Vq2jFt4czsq5wtrNJ4Zt4G5YIWWVn6elR1NrfGMOSXbyW/f2/4IOxvbMHz21Mx12dfNSW+oKv5EC4a0BevfvIFbho5BA9PT9/QZHLX7vj6+P644TnvC2oGd2qPd6862bS4qGNlKeqbWkyLwG4+eqjrjTf84ohO7bHmgPWA5jej+nXE69+fhOG3/tfxGoteFRX4sqHRPqOBvp0qpUpAWJwysLsp1v7QztVYecB6oxYVpw/qgenLrde63HreCNO+BW6gq+WjBtv4mVAx2sWFEJ5940uLg9ysPbCiPROGO2dFSbF9JgNebfwlxRG86D7iZNI2qG2oWfAzjrG6T/2aK4oJYR2Px2LDdz8Ev6oXpDgWhMeFU7K9chcAykvdX2Ov45PbHdmCRtaaTCb0nfQvqCvAgp9xjPVG297KNJ4XE3ItJ7XZt7oVfmiI1i6f5rQw3wTCcOesKI1r/O4EnkeNP2KCX0Ym+o6TuRL38ykO6w6kVCY/sZByfomgmBCeg1KVFhcFNuGpalOYsslL7JxMSQp+F1V71/ijL54ycVUtdnCfBxGgDWDBz/iE1wfAtMJWyMcXLZvVc1Dqh8bvMn+YexRkGkfeCxUlXkw93u4NP37PoMlkmoVNPYwn/vLeOtz4fGYhYVvaYjj3d+9hrkU4XgB4dv4G3Ppv9U6ZVs/2bw3eNx+u24UzHpqDxpY2k8ng6XkbTGVt39+IbfviXiEv68LpGnnho80ZX491dfJ1CqoH8NdvLs+ovkwwhkDOBpqN35Whx6Nw7FDhbp1JGNiFf7bCyfyQ9oblNyz4c5i7pi3HtCXbMipjR30Tlm3bj5+9ssQy322vWcclt9Lqfjt9ddr3O15fitU7DmBt3QGpUDAuSpIJ46B92Ad1b5f2PYpePWHQu2Ol63NiHtXi274ywtN5uYLRF2Hy0O6mPBce3SeQulnwFzianTGby+o1u6WqSuMkbRiry3t1NC4UY8kPAEf26WCfyYDXe6u6IlrLjPy2t+vnMM4c0RPtDW844w/rjJKAXJRZ8OcpTp81zcyYqUu4m4fbfoPy9AfMuAl5NsiBSCahkDRPuLg+Xi9llPZ4DgKjiT+bCg4L/gJGf6NletO5OT0pO5QRM9PTwohF5nQzlEJDm5B0487pVeOP2jX3WzCnB/iThRIPDseCn4gmEdHVic/dicj7OmImEsR0ESszXQXqSuPXLcKSin2Tb3/4Gn/EZFBoeBHGXm+tQrvmslXsQeFI8BPR7QB+BuCWRFIpgL8H1SgmO8SESArVTLVqN6drr/CqTcSNgj4MGz9beuQU2czPyPD6+wXlw+6VINsjRHb3c3Cq8X8VwPkADgKAEGIrAH83oGTS2LjrIFod7rC052Azdh9MD+/qREuOCZHU9GNCYF3dgeRDur+xBcu27sf+xhass4lsCQAihrTzrSAbI78xzvzGXdaRM/1m1fZ6fLJpT1raLsP1LVSSgt/FOV4XmkVM7geOX/s5OMGp4G8W8SdaAAARtbPJz2TA9v2NOPn+2bj7zRWO8o+5812MvfPdtDQnSpZe465vbMWpD87BUx9sAACcdN8snPvIexh1xzs49cE5tmXNXrUDpz44B68v3uqozYBaeBiX6v/qP8tMebbsCS5q45kPzzUJq1zZ3zZoAoyDZyJqcn/sAPPm6JkgW7yo56QhZvdOv3D6M/6TiB4H0ImIvgdgOoA/B9aqAkfT3uet3em5DCdiSgjzm8GijXFNd6/LxUGfbdkHAFi+zT5ErfZACyG38jtZ2LKj3n2Y37CxepArPAQ/A4BfnX8kPr3tDJRJVtROOqKb43IevnQ03vvp5OT3f91wgjRfNs0vqrqMayycMvf/JttnsmDKqGB86uOINDfm333jaPzg1MGB1ebobhNCPADgZQCvABgK4DYhxO8Da1WBo/d68YpTU49fimxjYoelcidL+nXmAlkzw4hBkw26ty9XHhvVz5s2OaBrFTpVlUmv+5Ce1ah0uPJzcI9qVJWl8prXMcTJZjRSVU2qttkxoGuV98bA/zcQ/bMnRLpf/5F9OgYWoA1wsBELERUDeFsIcTqAd+3yM5mjTX5m4s3i5FS9jT9TGlvi8xEyzdNISuOXv5mEEW44G1jJzEyX5st+77KSIscRLonSY8eoAogVJZWS4Adn1fUKK3ib34Oe8Rrqf6ugQ1LbXkEhRBuABiLqGGhLmCQe1shIcKLx+/cAN7Y41/hTz4+Q1t/icFI717B6lMs8BiTTQjPLrmNZMaHYYblFRGmmFXU0UveTu15RLeAKK3ab3y87xp9ML/iDjvrqdE10I4DPiOhdJDx7AEAI8QPVCUT0FIDzAOwQQhyVSOsC4EUANQA2ALhECLFHVUahoreBe8XZ5K6Ppp6Exu9I8CfrlwsQJ6aeXFxZayU4SjxqsVqETtnlKC0ucqylEqULG5XgyaqpR3FJwtqgxXfBr/vVBNJDlQR9nZ3ebdMA3ApgLoCFun9WPA3gbEPaVAAzhBCDAcxIfGcMkA9alROBHhP+eas0JW389iYLvTYpE+BO3Fiz6frmF1YhCJxq5ka0QVJmFiwtKXKsORYRpZt6FCdq41M2Bl5V08MT/P7Wa3z09IN/kPZ9wKHGL4R4hojKAAxJJK0UQli6fQgh5hJRjSH5AgCnJD4/A2A24gvDGB3J+8vi4ZIJx08370W7smLMXLEDJ0si/RnRL+DSmPbZNox9f72b5gIA3lsd90C6563lWFt3AF8b10+a72/zNyQ/P//RJjS1mvsxa6V1iGgAmLd2l+s2ho3lXgIeH3SrgdvNVpSEdC1TJeScbB7iF8o2hCT4/a5W/+gJIQwav791GXG6cvcUAKsBPAbgDwBWEdFJHurrKYTYBgCJvz0s6ryWiGqJqLauzl4Q5BMO5D6mL99uSrvwsQ/w1T/Mwz1vrXC0LZ9q5eydb5j95p2yp6EFj89dh2899ZH0+K2vLU3279VFX3gOK51Ppp7jD++KcYd19lTmqcPjj5B2PY7u3wk/O3sYjqnpjIvG9MXBpjaHbaO09qkEj53We8l4+YDvBa0mY1v0k7tlFoNb92q1F5W39jiTxmcd2ROXTeiPc0f2ssynf2stLiJce9Lhye9RMfU8COBMIcTJQoiTAJwF4OHgmgUIIZ4QQowXQozv3j24hQxRxsrGr7KGHEpMsjrxCBISjd8vrOz0hbYiM4W84y9ce5wjE5mRDfdOSW5Wol3tB74+CtefMggvXXcCOrcrwzkJ4aNaQ6CFPo7b+O1tzHaaqMot9Wvj+qFdmfOKkOYAACAASURBVLs+ak0wDjZ6q9gr18fXG8iE/K8vPMq2Dv3aBTucaOFH9GiPx68cj3suGoU/fHMcLhrTV5lX/+iVlRShd8dKtC9P/R5B4lTwlwohVmpfhBCrEI/X45btRNQbABJ/d3goI+8Rhr8y7G5CZ+6cwYU8tprkLdRVsFYPc6YDsKYkqAS2nSmpiCjNjKO08XuUSPEtNd2dq2nYxrNk9m9ZycZ9HTLGQXFuHDL0v7nRLBe0Sc2p4K8loieJ6JTEvz/DfnJXxusAvp34/G0Ar3koI+/R7gcrYWB3XzgR6DEhd6f0Ayt/fpldvxCw+sky/RW0n1GpqasEf/K89HtK7UPvVfAL1wugVG2QrU2Q9dvJIOVGvvrvx5/6rJmsUuatCEzuArgewI0AfoB42+YibutXQkQvID6R242ItgC4HcC9iId/+C6ATQC+7q3Z+Y0mjK1kskp70lKdbHfn58pdI1YbZRes4A9S40/89WqiIaT78avK8SqP4kG+vJ1rrFM2+Mja5WgzcxcdcpLT+Cta/ar6Y0lFKWnectwsTzgV/CUAfieEeAhIrua1nDkRQlymOHSa8+YVJklTj8VdY6cROBHo8VCwwUh+q/Zprp+FhtXkYKYvXtrAoVoOYHe/GA+rBxDrclTdiPmo8cuEtaxdTswlbtrkSAt38TvqB3tN8Gs1BL37mFNTzwwA+l2WKxEP1MYEgBPtT3VbaGc6saOLAG38Vn3QFnsVGlZyw68d0LwKbLPgl+cLw8ZvxGkYCmcav4v2+C2LJaae1KFg58GcCv4KIUQyKHvic2YRjxgl2kMsEwbXPPMxaqZOw1/nyX3t9fH1AeCLvYdw95vLAQBn/3YuTrl/VjJv3MbvZ8vN7ZChhXcoNKzkhl+uh25NNDITUd9OleqQDTYSQxWILiaEa8Gp5R/eO32Dd1kfPZt6XGjWTgYuk6lH94CNMPSjf5cq02etr0GvVXBq6jlIRGOFEIsAgIjGAwguIHqBowltmeicvjzuCPXBGusFTHqN+4m56/Dzc4djxZf1pjxBuXNaFRuUeSlozh3ZC29+9mVa2qs3nIB3l23HH2evNeX/6pi+uOK4w9C9fTnqm1rwUu0WZdlnHdkL3ztxIP78nnlAryorRkOzs8HSJC9E2h8lmkx75frjMaCLOuyxncZ/1pE9pelCuDfxlxYX4R/XHodhvapx9P9LxYdMX2imbpeT1a/G0167cSIueOwDU74ZPznZ0ZuG6s3tsgn98dOzhmHrvkOIxYCDza0Yd1hnjD+sM2JC4PTh8ev2xLfGY+nWfaiu8OI06Ryngv9mAC8R0VbE76E+AC4NrFUFTkrj916GE1OPnyEbzGVbrEHIxdVXAI6p6ZIm+KvKijF2QGdsUuwQNnlYj7SFWS9BLfiJCKcN7ykV/B0qSp0LfoVw0gukfp0rkxvZGL1Ixh3WJZmvc1Up9hj2ZdDyEcnvTyJCWXERmg0LTQREmsZcUVrkyOR33OFdJXXI6jWnebHx9+tcKc03qHt7R2+qqjt7wsAu6NyuDJ3blaWlnz4ifaDsWFmKEwY530fBK5YvbkR0DBH1EkJ8DGAY4gHWWgH8F4D7df2MI5KCPwM7n9MFXIGZeiwKztWoyyoxopyENHy3nRhVXDI3b/1uXRi1Kp1WobXFrZ95LOZfPHvZ9ZBO7jq5cIYsVsHy3ITA0IiqimPXk8cBaJuNHg/g54iHbdgD4IkA21XQJE09Gdw1ToRrTGTuRuil/qDqDBqjNm0nVoyyyOvkoJtJUZOsc3iqrA6rNLdBxOIav75Z3ocBabsk+bzY+K0WfTkpT3VrB+2l4xY7U0+xEGJ34vOlAJ4QQrwC4BUi+jTYphUuTlbu2uFI40dwfvyW4SZyVfArJ06dedLYPfqqNzxXi4yUph7r85zWoeWz1Pglh0Qmjvz2xUsTvXj1ZLra1/gbRvVWt9P4i4lIGxxOAzBTd8zp/ADjEl80ficrd2PB2fithHtUHwY7nJp0VOm2wlVp6nGj8XsT/FJPGUk+Lc1SqErqEvDRHVJm45dkc6bxp+N1XwTbeqKl8NsK7xcAzCGinYh78bwHAER0BIB9AbctZ9m69xC27DmECQO72GeWkHpIvUvIjYYJx1cXmScWY0Jgw66DpnQ/2L6/KZByw0T1uq5eaGT87m3xkxvXPnVkBnnp2puZ7DTZGUlTj0tB5iVkgwrZ7+B5AZcxAFyGbpS5otRYDm9CiF8D+Anim6pMEqn39yIANwXbtNzllAdm45LH53s+30nIBjvueWtF2vcf/3OxKU9rTGD19gOmdCYecuK8Ub3T0owy4abTBgOwst+6M/UM6VktTf/eiYdL02WoNP6RfeU7p2qCz6lGqgXfcysgLz1mAG6cfESyDLcacLf2KW8Y2bmyfvfoYL82wq4ZXxndx7YMPcZnNqrjgJM9dz8UQvxLCKHfcnGV5tPPmGnOMBaNdrMEPQna1NKGIgJ6VJdjw71TAq0rKnz8i9NNafddPMqUtvj2M/Ho5WPT0jThMmVkb2y4dwquO3kQALXQdKs8dq8uT/pz67n82AGOy1AJ/l4d5W6KKY3f2tQzsm9HbLh3StKzxdL8ZDj03k8n44wRPfHtE2qw4d4pWHnXOepzFdT+8gz8+IwhsuLjabrEUf3iba0qs7dG689be/e5puN3XnCk9NmYf8upGN1fHoI6Fwhnu3rGEm2BU9DaQmNrDG1CeHJTy1VkmqrMDGK5OtRowlHUZTQjOBnIM12w6cyD0aGR3KoeFw31277tZ3n6ayGf01CY9yLmpeOWwnnicwgnQdr8oLGlDbGYCG0ruzCQ2X2d2oxT9m2DCcfhpK+TefRMw/G6PT/px29zmnFwdOPH73eIYenbCVkLcIvCdGW4bIjkATV6swUV9jxTWPBHkJRXT7A3TWNLG9pEeHuYhoFTpw3ZNdGSnPm/mOtypPFn+ER63aTb1uHI0HQ394xfct+qGK9VpO9B4K5Pbp5OvzdqzxQW/FHEYXyVTGlqiSEWE4Fv7BwlnJt6zOdqz67ThVlGzdTJOB70Bhwq3AomqwHKWFI2+uT1WfE8YED+e0ZTvzfDgj+CJE0CAd9Fh1ra0FZgph6nQkgmCLUH3eSfryzEeL4TG39Igt/muEnjz3ADk0x6qR+opc1wpbl7bInKbTZHvHp4EVYEuPqvH+Hckb3xfy8vQUkR4a9XHwMAqG9qRc3UaTimpjM+3rDH93pvf30pAGBYL7kbYaHgdHK7JJGv0uAtYrcbmoYTG3+7cn8fycrS+Abnqh3RqitK0NDcZisr25Wnb5TeodJ59EjZ9amuKMVBh4HnUuW4yu6sTI8ZCCR9U1SuvnbXrMBhjT8CzFpZh/97eQmAuG+9UUAEIfT1aBr/K9efYLlJehD07FCOC49O+Uo/+50JOOvInnj08jFp+Ub3k/uhu+FHpw9BRWmxKX3KqN745rED8D8nmf3ln7vm2OTnc4/qhR+cNhg/P3dYWh7VQ203Cfz01cfgL98an5Z2y7nD8I1j+ie/P3TJaEXp6bx980m468KjTOlTzxmGH5x6BKaM7I3ffeNo0/EXrz0et543wtL18Wvj+plcWx+/chx+dvYwaX4nprB/XHscbj1vBP50Rapc428eBE9ffQyeuip1za0Gk19OGY6OigFOFZ00V2DBH0Gy7QmgCf5xh3XG01dPyGrd/3vmUEw9Z3jy+4SBXfD4leNNq54nDc48VO13JtVI00uKivDrr47ELecONx2beESq3pLiIvz4jCGmWOmOV+7qPp8xoidOGdrDFJa3Q0UpfnLm0OT3i8b2Szvev4vcH39or2pccdxhpvTqilL8+MyhKCkuwuh+nUztqunWDt+dNFDegQQ3Tj4CPTtUpKX17liJ608ZJM1vnNuQma+0eo9KLCzr07ECw3p1MOWTIbWt6xKttOtThvbAqcN66vKqc19jsXBOaeM37cRi0ZgQYcEfQbKtSegfTKtN0oOAiOTx1R0ID7d43YjcDqeTu07tyVZzLm7DIWeC16qMzbcqRvtNnMTyCcIzxu+IqapHN2JOPSz4o0hQgdNU6AVNSciLudSeM5k/OSqBmmnZKq3RWJ3TwctqIMrm5K9qMtsO4/W0arN2zM0qdasYQtmCFO3IFVjwh4zMrNOabcGve2hk28sF/UxR2mf5Iik/NN3A+qEq1yT4HRZn0dAwNEe3dZryW5yv5fXzlnfTXu8av/zZNXv1RHN4YMEfMrIbPlyN3/wkVJSYJ0R9RWrqSccPj9OgtGW13DdovrpOWLXE0tSTRddbvzwdrZqs1eHGvGln43eD19AL6vNUXj3RsvWw4Ldh14Em7G9ssc+YoF6Xt6lV7a5W39iCXQeapEK+Nct7E6YJfslTWlEa3G1CMMRLUZh6vK5I1ROUfVy9EYsxn7PyomLq0XArtEw7lVm9wSTKdhK22clckFuCvpxR9fxhwW/DuLum4/i7ZzjOf+J9s5Kfp77ymTLf5AdmY9xd06W2zWxvTViUJvjNt8TZR/UKtP7KstQbhdYSN3Zip2hFHOtyn4TDu7ezLldZn7oPx0o2EZflsyszWJzXpd+k3I3Gr60PMEYllUUplaGFaz55aHdl/Vao8lbbraeguBecEeXWi9FS+FnwO8HNQpO9DSmNf8by7cp8Ow/EtzKWCfnWtmzb+HWfJU+pzM1xysjepjSvtNc9ZKr48FZzzqcN64EPbznNlP7Ts4emfdfK/sM3x5ryWvHGTZOw6NYzlMfdunNefuwAfGdijavy/vk/x6eV4QX3d5VQtsfIOz86KXmNzFtOqguoKivBgp+fhru+mlqD0L68BI99U+3Tr7eb9+hQgfm3nIqfnjUMj185zr6hBmQD6ae3nYH5PzffT+nnAbeeNwJv/fBELP3VWZj+45MTbcsNeOVugDhR3GWmnjBt/LJVrLJFXR0qg7l1yPBXw0oL7lBZiq66jTo0+ihi0JdLFnFZUVVWgipz8UnUoXvT0frQu0OFpeYuM0lVJd6K/NAcg1A+9dfIaSwjDW2NgHZNurUvQ7lkXkl1nXsnfueu7Sx+JAWyEjtZ/di68ypKizG8d3ztQeeq+NoOc3RO103KCqzxB4jTfW+NZNurR3/7yzT+oPYhBdRCwigYrS4lkXxuQuVR4ff8qFrjN5p64n/tft6w4vWY8Tjx6TBsdVC4jbLpRx12dUblF9VgwR8gTsR3FGz8+pbKFnBl15NEc+dMT29uU094FxNZBlUz1eHzY6i28Ru/xxPsft/IyP0Ert05Dd+zNZB5eWq8zplE7CdyTSimHiLaAKAeQBuAViHEeOszchMn8lsm0LJt49droE6FfNBjk1E4W21nqWpz1ibaVBq/4Xtylaqt4I+WWHEdstlk43eH7a1lkyEbV081f2OO2BBNW0+YNv7JQoidIdYfOE4094NNraa0bNv49YLIaaTKwAW/C41f5eqZreXz6pW7cpOHl0sXVVuxDK8rlpPCMwc8Y8zhOOJ/c6HtAJt6LHnx402O8n20fjdeWbjFpJU2tcbwyIzVEEKgtS2G+/67AvPW7sTtr32ezNMg8Rj69ZvLM2u4S7xo/EFjEvxWGr/iqVINvL5vBejQqydl4/cuxUNZues2v0cbv9N8qquXzcFR1daobrVoJCzBLwC8Q0QLiehaWQYiupaIaomotq6uLsvNi/MzCz98PZc8Ph8/eWkx/v3pF6ZjD727Cut3HsS7y7bjD7PX4vI/L8Az8zcmjx9qcReT3C/0i7LOG5VyzZRNkgLA+aP7pH13+gr72OXuXCc19BrV6P6dcPKQ7sq8qsHqrBG90K5M5h3iL4d3b4fR/Tvhp2cPxeh+HdGjujxRT3pNlxzTH0f17SCNomnkzBE98Ued2+mQXu0x/rDOuPOCozBllDzEsh39OldiwsAuuO9rzkI9a3gdbH5x7nCcPKS7Y1NRn07x9t3/tVHS4xeP7YcRvTvg2yfUSI+P6tcRYwZ0wu1fOdJ07CrFOX7RoaIUE4/oiscMrsJRHQfCMvVMFEJsJaIeAN4lohVCiLn6DEKIJwA8AQDjx4+P6OVLp0VhjigpKkKb4g5QneMnb9w0Cef9/v3k96nnDEMxEX795nJcM2kgvj4+Ff+diNCtfTl2HmgCAEw8Ir7Q6OFLj8bri7cm8zm9oaeM6o3dB4/Era8tlR53oi2/duNEfLJJvSeBSoPvWFWK174/Cac/NAeHd2tnm98rPaor8NqNEwEAN5xyBCY/MBuobzL1rUd1Bd646URHZT5hiNNfXlKMl68/AQDw2OXmhUNOKC0uSq4HCBLNCey04T3wPckeByrs2te9uhxv/lB9/SpKi/GvGyZKj6n2DvCKbGX5c9ccZ3WGr/VnSigavxBia+LvDgD/ApDdIPABobL1FheTUthkYyLXWHWLhdnEiCbgMzIBeRC0Zvu4hd+75V1sDjGZLXNJ1Oy6XnEdsiGCHY9gk0Il64KfiNoRUbX2GcCZAD63Pis3UN1c8Q3N5QezofEbhbZ9nanBSKXZuxmuvIwZxlOsirASNLLQwkF7zWh23qgF5vJKpu6c+YjT3zaqpoowTD09Afwr8fCVAHheCPHfENrhO6pbISaEUvi1ZEHjNwrGZps6/bZLehGAblZ/WgVw07oSSnCzHJeAmS5uipLQy9aEvl/5gybrgl8IsQ6Au9mlHKctZI3fWLebOlWTuG4GB6ubXhnuwEW8F6uom5oHTTYfvDAHmyBw79UT/xuliU3/XXhzG3bn9JEWhf99TAiooh5E09STGUF4hHrV+JPnh/Co5oncd43ThWrZxPc1ew5/3AhdgjRY8Dtk5Zf1GHn727jmmVoAwJBfvIWbXvgkLc+t/5ZPVdzw3CLbyd3Dulb52Np0iijuEaHRo7o8+b1XxwpTfv29qrbxq+9o7YgW/qFb+3JlXo2eHezzqLDS+JM2/mxq/B63LMwXtH5nPeSUBX7P67h+C/K19szh6JwOmb92J+qbWjE9EWq5uS2G/yzeit9fpg4fq7Fq+wGl4NdWpP7s7GGY+soS7G80r+TNlCIiTLtpEjbsasDug004fXhPFBcRKkqLcMYIc6x9vaamf3bf+uGJeH3xVvxx9loAwPPfOxYNTW245tlaw/nxv5pr3enDeySPPXTJaOw+2Iy7pqUvUvvPTZOwYWeDsg/Gy/e3707AlU9+BCDl1fPfm09EU0sMFzz2QTKfarHU9ycfgUdnrTGlv/OjkzJ+SLVBMWqhF7ziVn6nVihHR/Jb/RIfTD0V2/c3uivP8U8bnWughzV+h2S6A5Sdjb+8pAg3Tj4iozqUdRcRenSowISBXXD2Ub1RUlwEIsLZR/W2d9PU3bfDe3fAEd3bJ9NPGNQNnS1C4WpvFUSEmsQbzdBe1bjmRLNvd4/qePtUGE01Jw5OLejSfpthvTpgdP9O6c1Pavzp56vqGtKzGoN7Vivb4YZcl/tem58y9fjXlkyx+i36dqrE2AHu1ka4HdSjpgSw4HdIUD+cJviLiiiwV2O3Ww5aNUObq3ASdkBfrSYMgrC1O+mfMUc2ZFK0HnX3eL1GTqOQZpOwBG+ELkEaLPgVxAxSWK8Yt3qYHFWv3I2nFxMF9qBkEk7f+LquCe7U5VG3Wf+Wk4qzn57H6fNoNSFt9daiXdMAtxQwof2M+eLV4xat11EVetlEuwRRuxNY8CswCmG9VtnoYuWrqjyNpMZPFJgXhJ8CyE2ESf01S2r8HpvSZHHNnWhzxjeNID1OwphQDgKvzY+iO2fYRO1eYMGvwGh20QvPRg+B1VSCJmXqAYLysnRt6hHyz+l57J/qIong90pTq/qaS/aOSRKm8MmXlbtuSdr4IzqxybDgBxAXvv/9/Ms0YWbU0PVy69l5G5Kfb3l1iaM63v5cvvH6G0u2AQjY1ONa8Mu9evRlOWkq6e4urQmyrSad0NTizdSTWkwlTw+SqGl52cLpFpOFQJTWMuhhwQ/gD7PW4rq/L8T05TuSaSZTj05yPDIz5Qb4wkebHdXxYq0838ZdcRfGoiLCaTq3Rz9xa9++QedddMVxA9KOHZ3wmrlobF/puXp//OI0G798wm9Mf2tvCi2c7vA+8U2tayTrHY4f1DXtOxFw4dHxMNKHdYnnv/L4Gst6GP/4VuJaD+gS3NqUfp0rcUyNvSfOdScPkqZfNmGANN2O60+Rl2dH1JQA9uMHsL0+7sO7oz7ly5ttbaWICKP6dcJnd5yJkXe8AwC456KRuOVV854AZ4zoiXeXpd4g/vDNsbjhuUXKst1G1rzu5EHKB6Z/lypsuHeKLiVV9m8uHolLjxmAmqnTABhNPenlpJchR5+nb6dK5TlH9Eh3v1x/Typf53ZllnVZxfn3SjJIW8Qe9mxx8bh+uHhcv0DreP9npzrKN/WcYZh6jjkk8z0XjcQ9F410Xe/Pzh7me4jnMGCNH0BZYgWQfpcno2Ya9HaImmDUT1Sq3hKNNns7uZ61za4N7ZW5c0bGxS8LzYia77ZXovKT5SJRvXQs+JEKLaB3GTS6cwZ982tauRPl3KjB2wmYsNwKZRp/1Oy+QVyaiHXRM3kybkWCqE30s+BHaoNxfYhko4AKWlPVhKTM992Ut8io8dsJ/sza5pW0ASpiGn82PE6i9ai7JyI/FRMALPiREvxWph5V5E2/cOPnbnRftBPsYW2gXkTmz1ETJkFcmaj1kQmPqN4LLPgBlJVoGr/a1NPsYdGWG1KmHgeLkUw2futzsmVrNt7jlGbq0dxAo/EkZKMZuW4qyfX2R4qIXcuC8+q5+q8f4bIJA3Dmkb3w0LursHjzXsxZVQcA+MPstXjx480Y1rsaq7cfSDvvzjeWBdouTSPWC/FSxWayxnuopJjQsbIU+w61pKUXF1Hgk9Jp7Uh0orSYTDuLVZUVA4ieMAliUMyXhUvtykoAmDeNZ5xTWRq/790uogyaghL8QgjMWlmHWSvrsOHeKXhkxmpTnl0Hm/HBml0Z1dOtfTl2HmgCABzevR3W1R1MO/6t4w/DkJ7V+KUufn+RZHL3gqP74H9fWmwqv2v7MtzxlREY2qsD5q/diYmDuuHRy8dg1oo6PPXBegDAo5ePweAe1Zi/dmdGfXHDhWPivv3TfnAi5q1Jr/fBS0bjuQ83uY6CaMUjl41Bdwex/mVkReOPmprnkme+MwHTPtuGnh3MezYwzrj7opEY0rM9Jh3RLeympFFQpp5sKb9v33xi8vMr151gOn7CoG644rjD0tKKkzZ+e43/2IFdcdXEgTh+UFf8+MyhKCoinDi4O277yohknvNG9cHQXtW4auLAjPpiT/yijhnQKdneIT3N9faorsCPzhjiq4Z9/ug+psVbbmEbv5r+XaqU6zkYZ3RpV5Z8RqNEQQn+bJk90twYJT+47B5w43JZkXh9jBLRuq3DJRmRkS8KE1EKSvBny5VQL8RlHjUyIe8mrEJFafR+tlxTcjkeP1PIRE+CBEjWNH7dVZVN6sg0wdzV+HNbvLFWzhQihSX4Q9D4ZZq8TMi78bVX2f4Z52QjHn+Oj4lMHpP3Xj37GloQEwLrdx3EvoaUu+OuhNdNEOjlutSNK0ONn7VUPwlkejdRMv9QTDTJe8E/+v+9I00fd9f0wOosIsJZR/bE20u3SzX5/p0rJec4L79TVWkmzWMQrI3/1GE98M/aLagsi5JJLjgi5rDCOCDvBX9Q/N9ZQ3H/2yvRu2MFHrxkNIb16oCG5lYUEaGitBiPXDYGew62gIjwya1nQABoaG6FEHE3OSNOTT3/+f4k9KhW+1V/etsZrGm6IIi3p19/dSRuPn0I2pfn/+P1ya1noNhqCzQmkuT/nRkQw3vHY8C3Ly/BCYPiizO6tCtLHi8vKUavjnGNr3MiXX/ciFM/3/5dzG8LejpVqetgskNpcRH6dLL+nfKFzhb3NBNdeJbQIyWJWVu/TAZObfyszftDviyyYhgvsOD3iGaa8WttgONYHiz3fYUvJ1OIhCL4iehsIlpJRGuIaGoYbciUpE3eJ83RqdzniTS/YJWfKVyyLviJqBjAYwDOATACwGVENML6rOhR4rfG71Ci58t2flGBLydTiISh8U8AsEYIsU4I0QzgHwAuCKKil2o3B1EsAL2px6fyHNv4GT9gGz9TyIQh+PsC0EvkLYm0NIjoWiKqJaLauro6TxW9sWSbtxY6oH+XKowd0Am/uXiU5zLu/9oolBUXYdIR3dI0z/NH98E9F40EAPzvmUPSzglr/1wVR/bpgCP7dMBt5+XWS9vEwd0wtGc1fnTGEPvMecjtXxmBi8f2C7sZTEhQtndEIqKvAzhLCHFN4vuVACYIIW5SnTN+/HhRW1vruq73V+/EFU8uMKUP790By7ftd1TGP649Dt944kNT+pI7zkSHiuwtpBr08zfRFhNYcefZEYvVwzBMVCGihUKI8cb0MDT+LQD66773A7A1iIpUUSzdDHYq23vUdtRhGIZxShiC/2MAg4loIBGVAfgGgNeDqEilGbt5yVHNuWbb5KINVlEz9TAMk3tkfeWuEKKViL4P4G0AxQCeEkIsDaIulcbvxhNH5UUTlvxluc8wTKaEErJBCPEmgDeDrqe8RK7xt7pwxVGZdMLSvFnuMwyTKXm9crdEETyqobnVcRlFRCiVlOMmfr6fsKmHYZhMyWvBX1Uqf6Hp1dF5AC2iuBeQKd1zq7wxpGd1lmtkGCZfyevonB2rSvHg10ejorQYxUVAt/bl+GDNLlw9qQaj7kjF6f/TFeMwoEsVzvv9e4iJVMhlIK5hP3P1BPxnyVY8/cEGrNt5EBeP7ec4mqZfPHfNsVi+rT7r9TIMk3/kteAHgIvHpS9SGV/TxZRn7IBO6NGhAoN7VGPl9nqcOqwH/jRnLeobW1FcROjcrgzfOr4GizbuwbqdBzHxiK7Zan6Sru3LMWlwedbrZRgm/8hrU49TjFo0UcqUoz+kefjwcn+GYXIZFvxIee4IXcRGxlRQcgAACANJREFUTchzUDSGYfINFvxIafyal6d+s5OwvHcYhmGCggU/zIuiiFJpaaae7DWJYRgmMFjwIyXQtbAIhJS/PPvNMwyTbxSs4L/iuAHJz1pMn6tOqAEA9OxYkRwMZHKf53YZhsll8t6dU8VdF47EXReOTEu78vgaXHl8TVpaMdt6GIbJMwpW47cjZeM3S/ts72HAMAzjJyz4lZDuf4ZhmPyBBT/DMEyBwYJfgWbh0Rt1NP9+NvQwDJPLsOBXkHLx1KWx3YdhmDyABb+CduVxhye9sC8viV+uEl7NyzBMDlOw7px2PHP1BLy++Av0qE5FxPzp2cPQvqIEXxndJ8SWMQzDZAblgmvi+PHjRW1tbdjNYBiGySmIaKEQYrwxnU09DMMwBQYLfoZhmAKDBT/DMEyBwYKfYRimwGDBzzAMU2Cw4GcYhikwWPAzDMMUGCz4GYZhCoycWMBFRHUANno8vRuAnT42Jypwv3IL7ldukS/9OkwI0d2YmBOCPxOIqFa2ci3X4X7lFtyv3CJf+6XBph6GYZgCgwU/wzBMgVEIgv+JsBsQENyv3IL7lVvka78AFICNn2EYhkmnEDR+hmEYRgcLfoZhmAIjrwU/EZ1NRCuJaA0RTQ27PU4hov5ENIuIlhPRUiL6YSK9CxG9S0SrE3876865JdHPlUR0Vnitt4eIionoEyJ6I/E9X/rViYheJqIVid/u+FzvGxH9KHEPfk5ELxBRRa72iYieIqIdRPS5Ls11X4hoHBF9ljj2CFEO7sYthMjLfwCKAawFcDiAMgCLAYwIu10O294bwNjE52oAqwCMAHAfgKmJ9KkAfpP4PCLRv3IAAxP9Lg67Hxb9+zGA5wG8kfieL/16BsA1ic9lADrlct8A9AWwHkBl4vs/AVyVq30CcBKAsQA+16W57guAjwAcD4AAvAXgnLD75vZfPmv8EwCsEUKsE0I0A/gHgAtCbpMjhBDbhBCLEp/rASxH/CG8AHHhgsTfCxOfLwDwDyFEkxBiPYA1iPc/chBRPwBTAPxFl5wP/eqAuGB5EgCEEM1CiL3I/b6VAKgkohIAVQC2Ikf7JISYC2C3IdlVX4ioN4AOQoj5Ij4KPKs7J2fIZ8HfF8Bm3fctibScgohqAIwBsABATyHENiA+OADokciWS339LYCfAojp0vKhX4cDqAPw14QZ6y9E1A453DchxBcAHgCwCcA2APuEEO8gh/skwW1f+iY+G9NzinwW/DK7W075rhJRewCvALhZCLHfKqskLXJ9JaLzAOwQQix0eookLXL9SlCCuBnhj0KIMQAOIm46UBH5viXs3RcgburoA6AdEV1hdYokLVJ9coGqL3nRx3wW/FsA9Nd974f4a2pOQESliAv954QQryaStydeNZH4uyORnit9nQjgfCLagLjp7VQi+jtyv19AvK1bhBALEt9fRnwgyOW+nQ5gvRCiTgjRAuBVACcgt/tkxG1ftiQ+G9NzinwW/B8DGExEA4moDMA3ALwecpsckfASeBLAciHEQ7pDrwP4duLztwG8pkv/BhGVE9FAAIMRn4CKFEKIW4QQ/YQQNYj/HjOFEFcgx/sFAEKILwFsJqKhiaTTACxDbvdtE4DjiKgqcU+ehvh8Uy73yYirviTMQfVEdFzimnxLd07uEPbscpD/AJyLuEfMWgC/CLs9Lto9CfHXxyUAPk38OxdAVwAzAKxO/O2iO+cXiX6uRA54GQA4BSmvnrzoF4CjAdQmfrd/A+ic630D8CsAKwB8DuBviHu55GSfALyA+FxFC+Ka+3e99AXA+MT1WAvgUSQiIOTSPw7ZwDAMU2Dks6mHYRiGkcCCn2EYpsBgwc8wDFNgsOBnGIYpMFjwMwzDFBgs+Jm8hojaiOhT3T/LKK1EdB0RfcuHejcQUTcP551FRHcQUWciejPTdjCMjJKwG8AwAXNICHG008xCiD8F2RgHnAhgFuIB3z4IuS1MnsKCnylIEmEjXgQwOZF0uRBiDRHdAeCAEOIBIvoBgOsAtAJYJoT4BhF1AfAU4kHZGgBcK4RYQkRdEV8g1B3x1aqkq+sKAD9APFTzAgA3CCHaDO25FMAtiXIvANATwH4iOlYIcX4Q14ApXNjUw+Q7lQZTz6W6Y/uFEBMQX335W8m5UwGMEUKMQnwAAOIrWT9JpP0c8bC8AHA7gPdFPEDb6wAGAAARDQdwKYCJiTePNgDfNFYkhHgRqVjxIxFfGTqGhT4TBKzxM/mOlannBd3fhyXHlwB4joj+jXgIBiAeTuNiABBCzCSirkTUEXHTzEWJ9GlEtCeR/zQA4wB8nNioqRKpQGBGBiMeBgAAqkR8LwaG8R0W/EwhIxSfNaYgLtDPB3ArER0J67C8sjIIwDNCiFusGkJEtQC6ASghomUAehPRpwBuEkK8Z90NhnEHm3qYQuZS3d/5+gNEVASgvxBiFuIbx3QC0B7AXCRMNUR0CoCdIr5Xgj79HMQDtAHxwF9fI6IeiWNdiOgwY0OEEOMBTEPcvn8f4kEFj2ahzwQBa/xMvlOZ0Jw1/iuE0Fw6y4loAeIK0GWG84oB/D1hxiEADwsh9iYmf/9KREsQn9zVQvr+CsALRLQIwBzEQxpDCLGMiH4J4J3EYNIC4EYAGyVtHYv4JPANAB6SHGcYX+DonExBkvDqGS+E2Bl2Wxgm27Cph2EYpsBgjZ9hGKbAYI2fYRimwGDBzzAMU2Cw4GcYhikwWPAzDMMUGCz4GYZhCoz/D/mpuCNvRSadAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.axhline(y=13.0, color='g', linestyle='-')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the score varies a lot from an episode to the next. It can be explained by the random nature of the environment itself: in some episodes, the agent starts surrounded by blue bananas and has a hard time getting all the way to the yellow ones in time to get a good score. Conversely, if most yellow bananas spawn near the agent's starting point, it will rack up a huge score that will be well above its average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and using a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_file_name):\n",
    "    \"\"\"Loads previously saved weights into an agent and lets it play one episode with training mode off\n",
    "    :param str model_file_name: path to the file containing the saved weights to load\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use CUDA if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize a new agent\n",
    "    agent = Agent(device)\n",
    "\n",
    "    # Load weights\n",
    "    agent.local_dqn.load_state_dict(torch.load(model_file_name))\n",
    "\n",
    "    # Reset environment\n",
    "    env_info = env.reset(train_mode=False)[brain_name]\n",
    "    \n",
    "    # Initialize variables\n",
    "    score = 0\n",
    "    done = False\n",
    "    state = env_info.vector_observations[0]\n",
    "    \n",
    "    # During the whole episode\n",
    "    while not done:\n",
    "        # Pick an action\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        # Perform the action on the environment\n",
    "        env_info = env.step(action)[brain_name]\n",
    "        \n",
    "        # Extract updated info from the environment\n",
    "        next_state = env_info.vector_observations[0]\n",
    "        reward = env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "        \n",
    "        # Update the score and state\n",
    "        score += reward\n",
    "        state = next_state\n",
    "    \n",
    "    print(\"Scored {}\".format(score))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored 14.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\"checkpoint-solved-1127.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the agent looks like in action:\n",
    "\n",
    "<img src=\"solved-1127.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing the Unity Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Udacity's DQN algorithm that solved OpenAI Gym's LunarLander worked for this Unity environment almost as-is. One minor adjustment (decreasing the learning rate sped up the agent's learning) and one major improvement (prioritized experience replay) were enough to meet the project's goals.\n",
    "\n",
    "Looking at the agent's behavior, it clearly seems to know that yellow bananas are desirable and blue bananas must be avoided. It sometimes jerks sideways and it is hard to tell whether it is a meaningless motion or if the agent is trying to better assess the positions of bananas in the environment to plan its next moves...\n",
    "\n",
    "Many potential improvements could be considered besides more fine-tuning of the hyper-parameters, including using Double DQNs, Dueling DQNs or switching to the Rainbow algorithm which incorporates all those improvements.\n",
    "\n",
    "It would be very helpful to be able to set the random seed of the environment itself. Without that feature, setting the random seeds in our algorithm will not ensure reproducible results. The randomness of the environment makes comparing different sets of hyperparameters a little bit harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Mnih, Volodymyr, et al. \"Human-level control through deep reinforcement learning\" Nature518.7540 (2015): 529 [PDF](http://www.davidqiu.com:8888/research/nature14236.pdf)\n",
    "2. Schaul, Tom, et al. \"Prioritized Experience Replay\" arXiv:1511.05952 cs.LG [PDF](https://arxiv.org/pdf/1511.05952)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "- The algorithm this one is based on is the [Deep Q-Network algorithm by Udacity](https://github.com/udacity/deep-reinforcement-learning/tree/master/dqn)\n",
    "- The neural network architecture diagram was generated with [NN SVG](http://alexlenail.me/NN-SVG/index.html)\n",
    "then edited with [Inkscape](https://inkscape.org/)\n",
    "- The GIF recordings were made with [ScreenToGif](https://www.screentogif.com/)\n",
    "- The notification sound was found on [WavSource.com](http://www.wavsource.com/video_games/pac-man.htm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "banana",
   "language": "python",
   "name": "banana"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
